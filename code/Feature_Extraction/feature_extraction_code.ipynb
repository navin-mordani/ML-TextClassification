{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Declaration of pre-processing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from stemming.porter2 import stem\n",
    "import re\n",
    "\n",
    "def splitText(text):\n",
    "     #split text by spaces and all symbols.\n",
    "    word_list = re.findall(r\"[\\w']+\", text)\n",
    "    word_list = [re.sub(r\"\\w*[\\d]+\\w*\", 'Numxyzabcd',s) for s in word_list]\n",
    "    return word_list\n",
    "\n",
    "def removeStopWords(word_list):\n",
    "    \"\"\" Removes stop words from text \"\"\"\n",
    "    \n",
    "    cachedStopWords = set(stopwords.words(\"english\"))    \n",
    "    filtered_words = [w for w in word_list if not w in cachedStopWords]    \n",
    "    return filtered_words\n",
    "\n",
    "def stemWords(word_list):\n",
    "    stemmedWords = [stem(w) for w in word_list]\n",
    "    return stemmedWords\n",
    "\n",
    "def preProcessData(abstract):\n",
    "    #preprocessing: stopword removal and stemming       \n",
    "    word_list = splitText(abstract)\n",
    "    word_list = removeStopWords(word_list)\n",
    "    word_list = stemWords(word_list)\n",
    "    return ' '.join(word_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'test number like Numxyzabcd Numxyzabcd Numxyzabcd Numxyzabcd Numxyzabcd Numxyzabcd hi'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = 'test that numbers like 1 2 3 + - 2 3 1 + , hi /'\n",
    "preProcessData(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Remove stop words and stem training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "#import training data and preprocess.\n",
    "df = pd.read_csv('../../data/train_in.csv')\n",
    "abstracts = df['abstract'].as_matrix()\n",
    "processedAbstracts = [preProcessData(a) for a in abstracts]\n",
    "pickle.dump(processedAbstracts, open('../../data/preProcessedListOfAbstracts.pkl',\"wb\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split into training and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#load training data and training labels.\n",
    "processedAbstracts = pickle.load(open('../../data/preProcessedListOfAbstracts.pkl',\"rb\"))\n",
    "processedAbstracts = np.asarray(processedAbstracts)  #convert to array.\n",
    "labels = pd.read_csv('../../data/train_out.csv')\n",
    "labels = labels['category'].as_matrix()\n",
    "\n",
    "#split into abstract_train, labels_train, abstract_test, labels_test.\n",
    "abstract_train, abstract_test, labels_train, labels_test = train_test_split(processedAbstracts, labels, test_size=0.2, \n",
    "                                                                            random_state=42)\n",
    "\n",
    "#save each\n",
    "pickle.dump(abstract_train, open('../../data/abstract_train.pkl',\"wb\"))\n",
    "pickle.dump(abstract_test, open('../../data/abstract_test.pkl',\"wb\"))\n",
    "pickle.dump(labels_train, open('../../data/labels_train.pkl',\"wb\"))\n",
    "pickle.dump(labels_test, open('../../data/labels_test.pkl',\"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70911,)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abstract_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2a: Vectorise (freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn import preprocessing\n",
    "\n",
    "\n",
    "#vectorise text\n",
    "processedAbstracts = pickle.load(open('../../data/abstract_train.pkl',\"rb\"))\n",
    "vectoriser = CountVectorizer(min_df=1, token_pattern=r'\\b\\w+\\b', binary=False, encoding=\"utf-8\")\n",
    "x_train = vectoriser.fit_transform(processedAbstracts)\n",
    "\n",
    "#import training label and encode\n",
    "labels = pickle.load(open('../../data/labels_train.pkl',\"rb\"))\n",
    "le = preprocessing.LabelEncoder()\n",
    "y_train = le.fit_transform(labels)\n",
    "\n",
    "#save\n",
    "pickle.dump(le, open('../../data/labelEncoder.pkl',\"wb\"))\n",
    "pickle.dump(vectoriser, open('../../data/vectoriser_freq.pkl',\"wb\"))\n",
    "pickle.dump(x_train, open('../../data/x_train_freq.pkl',\"wb\"))\n",
    "pickle.dump(y_train, open('../../data/y_train.pkl',\"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2b: Vectorise (binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "#vectorise text\n",
    "processedAbstracts = pickle.load(open('../../data/abstract_train.pkl',\"rb\"))\n",
    "vectoriser = CountVectorizer(min_df=1, token_pattern=r'\\b\\w+\\b', binary=True, encoding=\"utf-8\")\n",
    "x_train = vectoriser.fit_transform(processedAbstracts)\n",
    "\n",
    "\n",
    "pickle.dump(vectoriser, open('../../data/vectoriser_binary.pkl',\"wb\"))\n",
    "pickle.dump(x_train, open('../../data/x_train_binary.pkl',\"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Step 3: apply vectorisation on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle \n",
    "\n",
    "vectoriser_binary = pickle.load(open('data/vectoriser_binary.pkl',\"rb\"))\n",
    "vectoriser_freq = pickle.load(open('data/vectoriser_freq.pkl',\"rb\"))\n",
    "labelEncoder = pickle.load(open('data/labelEncoder.pkl',\"rb\"))\n",
    "\n",
    "abstract_test = pickle.load(open('data/abstract_test.pkl',\"rb\"))\n",
    "labels_test = pickle.load(open('data/labels_test.pkl',\"rb\"))\n",
    "\n",
    "x_test_binary = vectoriser_binary.transform(abstract_test)\n",
    "x_test_freq = vectoriser_freq.transform(abstract_test)\n",
    "y_test = labelEncoder.transform(labels_test)\n",
    "\n",
    "pickle.dump(x_test_binary, open('data/x_test_binary.pkl',\"wb\"))\n",
    "pickle.dump(x_test_freq, open('data/x_test_freq.pkl',\"wb\"))\n",
    "pickle.dump(y_test, open('data/y_test.pkl',\"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Step 4: vectorise entire dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn import preprocessing\n",
    "import pandas as pd\n",
    "\n",
    "#load training data and training labels.\n",
    "processedAbstracts = pickle.load(open('data/preProcessedListOfAbstracts.pkl',\"rb\"))\n",
    "processedAbstracts = np.asarray(processedAbstracts)  #convert to array.\n",
    "labels = pd.read_csv('data/train_out.csv')\n",
    "labels = labels['category'].as_matrix()\n",
    "\n",
    "vectoriser = CountVectorizer(min_df=1, token_pattern=r'\\b\\w+\\b', binary=True, encoding=\"utf-8\")\n",
    "x_train = vectoriser.fit_transform(processedAbstracts)\n",
    "\n",
    "#import training label and encode\n",
    "le = preprocessing.LabelEncoder()\n",
    "y_train = le.fit_transform(labels)\n",
    "\n",
    "#save\n",
    "pickle.dump(le, open('data_overall/labelEncoder.pkl',\"wb\"))\n",
    "pickle.dump(vectoriser, open('data_overall/vectoriser_binary.pkl',\"wb\"))\n",
    "pickle.dump(x_train, open('data_overall/x_train_binary.pkl',\"wb\"))\n",
    "pickle.dump(y_train, open('data_overall/y_train.pkl',\"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
